Here are the specific parts that can be improved with concrete code examples:

## 1. True Async State Management

**Problem**: Concurrent state modification without synchronization
**Fix**: Use asyncio locks and proper state management## 2. Proper Agent Communication with Message Queues

**Problem**: Superficial agent communication without real message passing
**Fix**: Implement proper message queues with async communication## 3. Resource Pool Management for LLM Access

**Problem**: Multiple agents trying to use the same LLM instance simultaneously
**Fix**: Implement proper resource pooling with queuingThese three improvements address the core architectural issues in your multi-agent system:

1. **Thread-Safe State Management**: Replaces the race condition-prone shared dictionary with proper async locks and event notifications
2. **Real Message Passing**: Creates actual queues and message handlers instead of superficial communication protocols  
3. **Resource Pool Management**: Prevents LLM access conflicts with proper queuing and concurrent access control

The key improvements:

**State Management**: Uses `asyncio.Lock()` for thread safety, implements proper state snapshots, and adds subscription-based notifications so agents can react to state changes immediately.

**Communication**: Creates real message queues with priority handling, proper message routing, and async message processing loops. Agents can now actually send requests and receive responses asynchronously.

**Resource Pooling**: Implements semaphore-based concurrent access control, request queuing with priority, retry logic, and comprehensive statistics tracking for LLM usage.

These changes would transform the codebase from a sequential workflow masquerading as multi-agent to a system with genuine concurrent agent behavior and proper inter-agent communication.



import asyncio
from typing import Dict, Any, Optional
from dataclasses import dataclass, field
import threading
import json
from copy import deepcopy

@dataclass
class ThreadSafeAgentState:
    """Thread-safe state management for multi-agent systems"""
    
    def __init__(self):
        self._state: Dict[str, Any] = {
            "user_input": "",
            "image_data": None,
            "agent_findings": {},
            "agent_confidence": {},
            "agent_requests": {},
            "workflow_phase": "analysis"
        }
        self._lock = asyncio.Lock()
        self._subscribers: Dict[str, list] = {}
    
    async def update_agent_finding(self, agent_name: str, findings: Dict[str, Any]):
        """Thread-safe agent findings update with notifications"""
        async with self._lock:
            if "agent_findings" not in self._state:
                self._state["agent_findings"] = {}
            
            self._state["agent_findings"][agent_name] = deepcopy(findings)
            
            # Notify subscribers
            await self._notify_subscribers(f"finding_updated_{agent_name}", findings)
    
    async def update_agent_confidence(self, agent_name: str, confidence: float):
        """Thread-safe confidence update"""
        async with self._lock:
            if "agent_confidence" not in self._state:
                self._state["agent_confidence"] = {}
            self._state["agent_confidence"][agent_name] = confidence
    
    async def add_agent_request(self, from_agent: str, to_agent: str, request: str):
        """Thread-safe request addition"""
        async with self._lock:
            if "agent_requests" not in self._state:
                self._state["agent_requests"] = {}
            if to_agent not in self._state["agent_requests"]:
                self._state["agent_requests"][to_agent] = []
            
            self._state["agent_requests"][to_agent].append({
                "from": from_agent,
                "request": request,
                "timestamp": asyncio.get_event_loop().time()
            })
            
            # Notify the target agent
            await self._notify_subscribers(f"request_{to_agent}", request)
    
    async def get_state_snapshot(self) -> Dict[str, Any]:
        """Get thread-safe state snapshot"""
        async with self._lock:
            return deepcopy(self._state)
    
    async def subscribe_to_updates(self, agent_name: str, event_type: str, callback):
        """Subscribe to state updates"""
        async with self._lock:
            key = f"{event_type}_{agent_name}"
            if key not in self._subscribers:
                self._subscribers[key] = []
            self._subscribers[key].append(callback)
    
    async def _notify_subscribers(self, event_key: str, data: Any):
        """Notify subscribers of state changes"""
        if event_key in self._subscribers:
            tasks = []
            for callback in self._subscribers[event_key]:
                if asyncio.iscoroutinefunction(callback):
                    tasks.append(callback(data))
                else:
                    # Run sync callbacks in thread pool
                    tasks.append(asyncio.get_event_loop().run_in_executor(None, callback, data))
            
            if tasks:
                await asyncio.gather(*tasks, return_exceptions=True)




import asyncio
from dataclasses import dataclass, field
from typing import Dict, List, Any, Optional, Callable
from enum import Enum
import time
import json

class MessageType(Enum):
    REQUEST = "request"
    RESPONSE = "response"
    FINDING = "finding"
    COLLABORATION = "collaboration"
    URGENT = "urgent"

@dataclass
class AgentMessage:
    """Structured message between agents"""
    from_agent: str
    to_agent: str
    message_type: MessageType
    content: Any
    confidence: float = 0.0
    timestamp: float = field(default_factory=time.time)
    correlation_id: Optional[str] = None
    requires_response: bool = False

class MessageBroker:
    """Async message broker for agent communication"""
    
    def __init__(self):
        self._queues: Dict[str, asyncio.Queue] = {}
        self._subscribers: Dict[str, List[Callable]] = {}
        self._message_handlers: Dict[str, Dict[MessageType, Callable]] = {}
        self._running = False
    
    async def start(self):
        """Start the message broker"""
        self._running = True
        print("Message Broker: Started")
    
    async def stop(self):
        """Stop the message broker"""
        self._running = False
        print("Message Broker: Stopped")
    
    def register_agent(self, agent_name: str):
        """Register an agent with the broker"""
        if agent_name not in self._queues:
            self._queues[agent_name] = asyncio.Queue(maxsize=100)
            self._message_handlers[agent_name] = {}
            print(f"Message Broker: Registered agent {agent_name}")
    
    def register_handler(self, agent_name: str, message_type: MessageType, handler: Callable):
        """Register a message handler for an agent"""
        if agent_name not in self._message_handlers:
            self._message_handlers[agent_name] = {}
        self._message_handlers[agent_name][message_type] = handler
    
    async def send_message(self, message: AgentMessage):
        """Send message to target agent"""
        if message.to_agent not in self._queues:
            print(f"Message Broker: Agent {message.to_agent} not registered")
            return
        
        try:
            await self._queues[message.to_agent].put(message)
            print(f"Message Broker: Sent {message.message_type.value} from {message.from_agent} to {message.to_agent}")
        except asyncio.QueueFull:
            print(f"Message Broker: Queue full for agent {message.to_agent}")
    
    async def receive_messages(self, agent_name: str) -> List[AgentMessage]:
        """Receive all pending messages for an agent"""
        if agent_name not in self._queues:
            return []
        
        messages = []
        queue = self._queues[agent_name]
        
        # Get all available messages without blocking
        while not queue.empty():
            try:
                message = queue.get_nowait()
                messages.append(message)
                queue.task_done()
            except asyncio.QueueEmpty:
                break
        
        return messages
    
    async def broadcast_message(self, message: AgentMessage, exclude_sender: bool = True):
        """Broadcast message to all agents"""
        for agent_name in self._queues.keys():
            if exclude_sender and agent_name == message.from_agent:
                continue
            
            broadcast_msg = AgentMessage(
                from_agent=message.from_agent,
                to_agent=agent_name,
                message_type=message.message_type,
                content=message.content,
                confidence=message.confidence
            )
            await self.send_message(broadcast_msg)

class CommunicatingAgent:
    """Base agent class with proper communication capabilities"""
    
    def __init__(self, name: str, message_broker: MessageBroker):
        self.name = name
        self.broker = message_broker
        self.broker.register_agent(name)
        self.is_running = False
        self._setup_message_handlers()
    
    def _setup_message_handlers(self):
        """Setup message handlers for different message types"""
        self.broker.register_handler(self.name, MessageType.REQUEST, self._handle_request)
        self.broker.register_handler(self.name, MessageType.RESPONSE, self._handle_response)
        self.broker.register_handler(self.name, MessageType.FINDING, self._handle_finding)
        self.broker.register_handler(self.name, MessageType.URGENT, self._handle_urgent)
    
    async def start(self):
        """Start the agent's message processing loop"""
        self.is_running = True
        await self._message_processing_loop()
    
    async def stop(self):
        """Stop the agent"""
        self.is_running = False
    
    async def send_message(self, to_agent: str, message_type: MessageType, content: Any, 
                          requires_response: bool = False):
        """Send a message to another agent"""
        message = AgentMessage(
            from_agent=self.name,
            to_agent=to_agent,
            message_type=message_type,
            content=content,
            requires_response=requires_response
        )
        await self.broker.send_message(message)
    
    async def broadcast_finding(self, findings: Dict[str, Any]):
        """Broadcast findings to all other agents"""
        message = AgentMessage(
            from_agent=self.name,
            to_agent="all",
            message_type=MessageType.FINDING,
            content=findings
        )
        await self.broker.broadcast_message(message)
    
    async def request_collaboration(self, target_agent: str, request_content: str):
        """Request collaboration from specific agent"""
        await self.send_message(
            target_agent, 
            MessageType.REQUEST, 
            request_content,
            requires_response=True
        )
    
    async def _message_processing_loop(self):
        """Main message processing loop"""
        while self.is_running:
            # Process incoming messages
            messages = await self.broker.receive_messages(self.name)
            
            for message in messages:
                try:
                    handler = self.broker._message_handlers[self.name].get(message.message_type)
                    if handler:
                        await handler(message)
                    else:
                        print(f"{self.name}: No handler for {message.message_type}")
                except Exception as e:
                    print(f"{self.name}: Error processing message: {e}")
            
            # Do agent work
            await self._do_work()
            
            # Small delay to prevent CPU spinning
            await asyncio.sleep(0.1)
    
    async def _do_work(self):
        """Override in subclasses for agent-specific work"""
        pass
    
    # Message handlers - override in subclasses
    async def _handle_request(self, message: AgentMessage):
        """Handle incoming requests"""
        print(f"{self.name}: Received request from {message.from_agent}: {message.content}")
    
    async def _handle_response(self, message: AgentMessage):
        """Handle incoming responses"""
        print(f"{self.name}: Received response from {message.from_agent}")
    
    async def _handle_finding(self, message: AgentMessage):
        """Handle incoming findings from other agents"""
        print(f"{self.name}: Received findings from {message.from_agent}")
    
    async def _handle_urgent(self, message: AgentMessage):
        """Handle urgent messages"""
        print(f"{self.name}: URGENT message from {message.from_agent}: {message.content}")

# Example usage of improved communication system
class ImprovedVisionAgent(CommunicatingAgent):
    """Vision agent with proper communication"""
    
    def __init__(self, message_broker: MessageBroker):
        super().__init__("vision", message_broker)
        self.analysis_complete = False
        self.current_findings = {}
    
    async def _do_work(self):
        """Vision agent work with communication"""
        if not self.analysis_complete:
            # Simulate analysis work
            await asyncio.sleep(0.5)
            
            self.current_findings = {
                "device": "iPhone 12",
                "problem": "cracked screen",
                "confidence": 0.85
            }
            
            # Broadcast findings to other agents
            await self.broadcast_finding(self.current_findings)
            
            # Request technical details from research agent
            await self.request_collaboration(
                "research", 
                f"Need repair guides for {self.current_findings['device']}"
            )
            
            self.analysis_complete = True
    
    async def _handle_request(self, message: AgentMessage):
        """Handle requests from other agents"""
        if "clarification" in str(message.content).lower():
            # Send clarification
            await self.send_message(
                message.from_agent,
                MessageType.RESPONSE,
                {"clarification": self.current_findings},
                requires_response=False
            )

# Usage example
async def demo_improved_communication():
    """Demonstrate improved agent communication"""
    broker = MessageBroker()
    await broker.start()
    
    # Create agents
    vision_agent = ImprovedVisionAgent(broker)
    
    # Start agents (would run in parallel)
    vision_task = asyncio.create_task(vision_agent.start())
    
    # Let them run for a bit
    await asyncio.sleep(2)
    
    # Stop agents
    await vision_agent.stop()
    await broker.stop()
    
    vision_task.cancel()
    
    print("Communication demo completed")


import asyncio
from typing import Dict, List, Any, Optional
import time
from dataclasses import dataclass
from contextlib import asynccontextmanager

@dataclass
class LLMRequest:
    """Request for LLM processing"""
    agent_name: str
    messages: List[Any]
    temperature: float = 0.7
    max_tokens: Optional[int] = None
    priority: int = 1  # Lower number = higher priority
    timestamp: float = 0.0

class LLMResourcePool:
    """Thread-safe resource pool for LLM access"""
    
    def __init__(self, max_concurrent: int = 3):
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.request_queue = asyncio.PriorityQueue()
        self.active_requests: Dict[str, LLMRequest] = {}
        self.llm_instances = {}
        self._stats = {
            "total_requests": 0,
            "completed_requests": 0,
            "failed_requests": 0,
            "queue_waits": []
        }
    
    def add_llm_instance(self, name: str, llm_instance):
        """Add LLM instance to the pool"""
        self.llm_instances[name] = llm_instance
        print(f"LLM Pool: Added {name} instance")
    
    @asynccontextmanager
    async def get_llm(self, agent_name: str, priority: int = 1):
        """Context manager for getting LLM access with queuing"""
        request = LLMRequest(
            agent_name=agent_name,
            messages=[],
            priority=priority,
            timestamp=time.time()
        )
        
        # Add to queue with priority
        await self.request_queue.put((priority, time.time(), request))
        self._stats["total_requests"] += 1
        
        # Wait for semaphore (concurrent access control)
        async with self.semaphore:
            # Get from queue (FIFO within same priority)
            _, _, queued_request = await self.request_queue.get()
            
            queue_wait_time = time.time() - queued_request.timestamp
            self._stats["queue_waits"].append(queue_wait_time)
            
            try:
                self.active_requests[agent_name] = queued_request
                
                # Get appropriate LLM instance (round-robin or least loaded)
                llm_instance = self._get_available_llm()
                
                print(f"LLM Pool: {agent_name} acquired LLM (waited {queue_wait_time:.2f}s)")
                yield llm_instance
                
                self._stats["completed_requests"] += 1
                
            except Exception as e:
                self._stats["failed_requests"] += 1
                print(f"LLM Pool: Error for {agent_name}: {e}")
                raise
            finally:
                # Clean up
                if agent_name in self.active_requests:
                    del self.active_requests[agent_name]
                self.request_queue.task_done()
                print(f"LLM Pool: {agent_name} released LLM")
    
    def _get_available_llm(self):
        """Get available LLM instance"""
        if "default" in self.llm_instances:
            return self.llm_instances["default"]
        elif self.llm_instances:
            return next(iter(self.llm_instances.values()))
        else:
            raise RuntimeError("No LLM instances available")
    
    async def process_with_retry(self, agent_name: str, messages: List[Any], 
                               max_retries: int = 3, priority: int = 1):
        """Process request with automatic retry logic"""
        for attempt in range(max_retries):
            try:
                async with self.get_llm(agent_name, priority) as llm:
                    result = llm.invoke(messages)
                    return result
            except Exception as e:
                print(f"LLM Pool: Attempt {attempt + 1} failed for {agent_name}: {e}")
                if attempt == max_retries - 1:
                    raise
                await asyncio.sleep(0.5 * (attempt + 1))  # Exponential backoff
    
    def get_stats(self) -> Dict[str, Any]:
        """Get pool statistics"""
        avg_wait = sum(self._stats["queue_waits"]) / len(self._stats["queue_waits"]) if self._stats["queue_waits"] else 0
        
        return {
            "active_requests": len(self.active_requests),
            "queue_size": self.request_queue.qsize(),
            "total_requests": self._stats["total_requests"],
            "completed_requests": self._stats["completed_requests"],
            "failed_requests": self._stats["failed_requests"],
            "average_queue_wait": avg_wait,
            "success_rate": (self._stats["completed_requests"] / max(self._stats["total_requests"], 1)) * 100
        }

# Improved agent base class with resource pool
class ResourceAwareAgent:
    """Agent that properly uses LLM resource pool"""
    
    def __init__(self, name: str, llm_pool: LLMResourcePool, priority: int = 1):
        self.name = name
        self.llm_pool = llm_pool
        self.priority = priority
        self.processing_stats = {
            "llm_calls": 0,
            "total_processing_time": 0.0
        }
    
    async def process_with_llm(self, messages: List[Any], high_priority: bool = False):
        """Process messages using the LLM pool"""
        priority = 0 if high_priority else self.priority
        start_time = time.time()
        
        try:
            result = await self.llm_pool.process_with_retry(
                self.name, 
                messages, 
                priority=priority
            )
            
            processing_time = time.time() - start_time
            self.processing_stats["llm_calls"] += 1
            self.processing_stats["total_processing_time"] += processing_time
            
            return result
            
        except Exception as e:
            print(f"Agent {self.name}: LLM processing failed: {e}")
            return None
    
    def get_processing_stats(self):
        """Get agent's processing statistics"""
        avg_time = (self.processing_stats["total_processing_time"] / 
                   max(self.processing_stats["llm_calls"], 1))
        
        return {
            "agent": self.name,
            "llm_calls": self.processing_stats["llm_calls"],
            "average_processing_time": avg_time,
            "total_processing_time": self.processing_stats["total_processing_time"]
        }

# Example improved vision agent with resource management
class ResourceAwareVisionAgent(ResourceAwareAgent):
    """Vision agent with proper resource management"""
    
    def __init__(self, llm_pool: LLMResourcePool):
        super().__init__("vision", llm_pool, priority=1)  # High priority for vision
        self.analysis_stages = ["initial", "device_id", "problem_assess", "safety"]
        self.current_stage = 0
        self.findings = {}
    
    async def analyze_image(self, image_data: str, user_input: str):
        """Analyze image using staged approach with resource management"""
        
        for stage in self.analysis_stages:
            stage_prompt = self._get_stage_prompt(stage, image_data, user_input)
            
            # Process with appropriate priority
            high_priority = (stage == "safety")  # Safety analysis gets highest priority
            
            result = await self.process_with_llm([stage_prompt], high_priority)
            
            if result:
                self.findings[stage] = result.content
                print(f"Vision Agent: Completed {stage} analysis")
            else:
                print(f"Vision Agent: Failed {stage} analysis")
                break
            
            # Small delay between stages to allow other agents to work
            await asyncio.sleep(0.1)
        
        return self.findings
    
    def _get_stage_prompt(self, stage: str, image_data: str, user_input: str):
        """Get prompt for specific analysis stage"""
        prompts = {
            "initial": f"Analyze this repair image: {user_input}",
            "device_id": f"Identify the exact device in this image: {self.findings.get('initial', '')}",
            "problem_assess": f"Assess the problem severity: {self.findings.get('device_id', '')}",
            "safety": f"Identify safety concerns: {self.findings.get('problem_assess', '')}"
        }
        return {"role": "user", "content": prompts.get(stage, "")}

# Usage example
async def demo_resource_management():
    """Demonstrate resource pool usage"""
    from langchain_ollama import ChatOllama
    
    # Create resource pool
    llm_pool = LLMResourcePool(max_concurrent=2)
    
    # Add LLM instances
    llm_pool.add_llm_instance("default", ChatOllama(model="qwen2.5vl:7b"))
    
    # Create agents
    vision_agent = ResourceAwareVisionAgent(llm_pool)
    
    # Simulate concurrent processing
    tasks = []
    for i in range(3):
        task = vision_agent.analyze_image(f"image_data_{i}", f"repair request {i}")
        tasks.append(task)
    
    # Wait for all to complete
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Print statistics
    print("Resource Pool Stats:", llm_pool.get_stats())
    print("Agent Stats:", vision_agent.get_processing_stats())
    
    return results
